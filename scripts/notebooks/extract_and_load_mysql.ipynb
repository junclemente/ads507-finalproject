{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Washington State DOT Traffic API\n",
    "\n",
    "source: [https://wsdot.wa.gov/traffic/api](https://wsdot.wa.gov/traffic/api)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from time import sleep\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import env variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# API variables\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "# MySQL database variables\n",
    "db_user = os.getenv(\"AZURE_USERNAME\")\n",
    "db_pwd = os.getenv(\"AZURE_PWD\")\n",
    "db_host = os.getenv(\"AZURE_URL\")\n",
    "db_port = os.getenv(\"AZURE_PORT\")\n",
    "db_database = os.getenv(\"AZURE_DB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs to Access APIs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAVEL_TIMES_URL = \"http://wsdot.wa.gov/Traffic/api/TravelTimes/TravelTimesREST.svc/GetTravelTimesAsJson?AccessCode={ACCESSCODE}\"\n",
    "\n",
    "TRAFFIC_ALERTS_URL = \"http://www.wsdot.wa.gov/Traffic/api/HighwayAlerts/HighwayAlertsREST.svc/GetAlertsAsJson?AccessCode={ACCESSCODE}\"\n",
    "\n",
    "WEATHER_INFORMATION_URL = \"http://wsdot.wa.gov/Traffic/api/WeatherInformation/WeatherInformationREST.svc/GetCurrentWeatherInformationAsJson?AccessCode={ACCESSCODE}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database engine\n",
    "connection_url = (\n",
    "    f\"mysql+pymysql://{db_user}:{db_pwd}\" f\"@{db_host}:{db_port}/{db_database}\"\n",
    ")\n",
    "engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes and Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class: MySQLLogHandler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySQLLogHandler(logging.Handler):\n",
    "    \"\"\"\n",
    "    A custom logging handler that stores log records in a MySQL database\n",
    "    developed with the help of ChatGPT.\n",
    "\n",
    "    This handler extends `logging.Handler` and writes log messages to a MySQL table\n",
    "    in real time. It utilizes an SQLAlchemy database engine for executing inserts.\n",
    "\n",
    "    Attributes:\n",
    "        engine (sqlalchemy.engine.base.Engine): The SQLAlchemy database engine used\n",
    "            to establish a connection with the MySQL database.\n",
    "        formatter (logging.Formatter): The formatter used to format log messages.\n",
    "\n",
    "    Methods:\n",
    "        emit(record):\n",
    "            Inserts a log record into the `application_logs` table in the MySQL database.\n",
    "            Logs include timestamp, log level, and formatted message.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        import logging\n",
    "        from sqlalchemy import create_engine\n",
    "        from your_module import MySQLLogHandler\n",
    "\n",
    "        engine = create_engine(\"mysql+pymysql://user:password@localhost/dbname\")\n",
    "\n",
    "        logger = logging.getLogger(\"app_logger\")\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        db_handler = MySQLLogHandler(engine)\n",
    "        logger.addHandler(db_handler)\n",
    "\n",
    "        logger.info(\"This is an info log message.\")\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db_engine):\n",
    "        super().__init__()\n",
    "        self.engine = db_engine\n",
    "        self.formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "    def emit(self, record):\n",
    "        \"\"\"Inserts log records into MySQL in real time.\"\"\"\n",
    "        try:\n",
    "            # log_time = self.formatter.formatTime(record, self.formatter.datefmt)\n",
    "            log_level = record.levelname\n",
    "            log_message = self.format(record)\n",
    "\n",
    "            with self.engine.begin() as conn:\n",
    "                query = \"\"\"\n",
    "                    INSERT INTO application_logs (log_timestamp, log_level, log_message)\n",
    "                    VALUES (NOW(), :log_level, :log_message)\n",
    "                \"\"\"\n",
    "                conn.execute(\n",
    "                    text(query), {\"log_level\": log_level, \"log_message\": log_message}\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to insert log into MySQL: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging to use MySQLLogHandler\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        MySQLLogHandler(engine),\n",
    "        # logging.FileHandler(\"app.log\"),\n",
    "        logging.StreamHandler(),\n",
    "    ],\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: get_api_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 54 (1790919589.py, line 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 55\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 54\n"
     ]
    }
   ],
   "source": [
    "def get_api_data(url, access_key):\n",
    "    \"\"\"\n",
    "    Fetches data from an API and returns it as a Pandas DataFrame.\n",
    "\n",
    "    This function sends a GET request to the specified API endpoint using the provided\n",
    "    access key. If the request is successful (status code 200), the JSON response is\n",
    "    converted into a Pandas DataFrame. Otherwise, an error message is logged.\n",
    "\n",
    "    Args:\n",
    "        url (str): The API endpoint URL containing a placeholder `{ACCESSCODE}`\n",
    "            for the access key.\n",
    "        access_key (str): The access key required for authentication with the API.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: The retrieved data as a Pandas DataFrame if the request is successful.\n",
    "            - int: The HTTP response status code.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        url = \"https://api.example.com/data?key={ACCESSCODE}\"\n",
    "        access_key = \"your_api_key\"\n",
    "\n",
    "        df, status_code = get_api_data(url, access_key)\n",
    "\n",
    "        if status_code == 200:\n",
    "            print(\"Data fetched successfully!\")\n",
    "            print(df.head())\n",
    "        else:\n",
    "            print(f\"Failed to fetch data. Status code: {status_code}\")\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "\n",
    "    # create the url with the access key\n",
    "    url_api = url.format(ACCESSCODE=access_key)\n",
    "    response = requests.get(url_api)\n",
    "\n",
    "    # check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        logging.info(\"Data fetched successfully.\")\n",
    "        data = response.json()\n",
    "        df = pd.DataFrame(data)\n",
    "    else:\n",
    "        logging.error(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "\n",
    "    # return the dataframe and the status code\n",
    "    return df, response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: convert_dict_to_json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_to_json(dataframe):\n",
    "    \"\"\"\n",
    "    Converts dictionary-type values in a Pandas DataFrame to JSON strings.\n",
    "    Developed with help of ChatGPT.\n",
    "\n",
    "    This function iterates through each column in the DataFrame and checks if all\n",
    "    values in the column are dictionaries. If a column contains only dictionaries,\n",
    "    it converts each dictionary into a JSON-formatted string.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing potential dictionary-type values.\n",
    "\n",
    "    Returns:\n",
    "        None: The function modifies the DataFrame in place.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        import pandas as pd\n",
    "\n",
    "        data = {\n",
    "            \"col1\": [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}],\n",
    "            \"col2\": [123, 456]\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        convert_dict_to_json(df)\n",
    "\n",
    "        print(df)\n",
    "        # Output:\n",
    "        #                           col1  col2\n",
    "        # 0  {\"key1\": \"value1\"}   123\n",
    "        # 1  {\"key2\": \"value2\"}   456\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "\n",
    "    for col in dataframe.columns:\n",
    "        if dataframe[col].apply(lambda x: isinstance(x, dict)).all():\n",
    "            dataframe[col] = dataframe[col].apply(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: upload_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_dataframe(dataframe, table_name, conn, mode=\"append\"):\n",
    "    \"\"\"\n",
    "    Uploads a Pandas DataFrame to a SQL database table.\n",
    "\n",
    "    This function inserts data from a Pandas DataFrame into a specified SQL table\n",
    "    using SQLAlchemy. It supports different insertion modes, such as 'append' or\n",
    "    'replace'. If the upload is successful, a log message is recorded. If an error\n",
    "    occurs, an error message is logged.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The DataFrame to be uploaded to the database.\n",
    "        table_name (str): The name of the target SQL table.\n",
    "        conn (sqlalchemy.engine.base.Engine or sqlalchemy.Connection):\n",
    "            The SQLAlchemy database connection or engine.\n",
    "        mode (str, optional): Specifies the insertion mode:\n",
    "            - `\"append\"` (default): Adds new records without removing existing ones.\n",
    "            - `\"replace\"`: Drops the table and creates a new one with the DataFrame.\n",
    "            - `\"fail\"`: Raises an error if the table already exists.\n",
    "\n",
    "    Returns:\n",
    "        None: The function uploads data to the database but does not return a value.\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        import pandas as pd\n",
    "        from sqlalchemy import create_engine\n",
    "\n",
    "        # Sample data\n",
    "        data = {\"id\": [1, 2, 3], \"name\": [\"Alice\", \"Bob\", \"Charlie\"]}\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(\"sqlite:///example.db\")\n",
    "\n",
    "        # Upload DataFrame to SQL table\n",
    "        upload_dataframe(df, \"users\", engine, mode=\"append\")\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataframe.to_sql(\n",
    "            table_name,\n",
    "            con=conn,\n",
    "            if_exists=mode,\n",
    "            index=False,\n",
    "        )\n",
    "        logging.info(f\"{table_name} ({mode}) uploaded successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to upload {table_name}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: api_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_update(\n",
    "    travel_times_url, traffic_alerts_url, weather_information_url, access_key\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetches and updates travel times, traffic alerts, and weather information from APIs.\n",
    "\n",
    "    This function retrieves data from three API endpoints (travel times, traffic alerts,\n",
    "    and weather information) using the provided access key. The retrieved data is\n",
    "    processed, timestamped, and formatted before being returned.\n",
    "\n",
    "    Args:\n",
    "        travel_times_url (str): The API URL for fetching travel time data.\n",
    "        traffic_alerts_url (str): The API URL for fetching traffic alert data.\n",
    "        weather_information_url (str): The API URL for fetching weather information.\n",
    "        access_key (str): The API access key required for authentication.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - pd.DataFrame: `df_api_fetch` - A summary DataFrame containing response\n",
    "              statuses and timestamps.\n",
    "            - pd.DataFrame: `df_tt` - The travel times data with a timestamp column.\n",
    "            - pd.DataFrame: `df_ta` - The traffic alerts data with a timestamp column.\n",
    "            - pd.DataFrame: `df_wa` - The weather information data with a timestamp column.\n",
    "            - str: The status of the API fetch operation (\"Success\" or \"Failed\").\n",
    "\n",
    "    Example:\n",
    "        ```python\n",
    "        travel_url = \"https://api.example.com/travel_times?key={ACCESSCODE}\"\n",
    "        traffic_url = \"https://api.example.com/traffic_alerts?key={ACCESSCODE}\"\n",
    "        weather_url = \"https://api.example.com/weather_info?key={ACCESSCODE}\"\n",
    "        access_key = \"your_api_key\"\n",
    "\n",
    "        df_api_fetch, df_tt, df_ta, df_wa, status = api_update(\n",
    "            travel_url, traffic_url, weather_url, access_key\n",
    "        )\n",
    "\n",
    "        print(df_api_fetch)\n",
    "        print(f\"API update status: {status}\")\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "    # Get current time\n",
    "    timestamp = pd.Timestamp.now()\n",
    "    df_tt, response_tt = get_api_data(travel_times_url, access_key)\n",
    "    df_ta, response_ta = get_api_data(traffic_alerts_url, access_key)\n",
    "    df_wa, response_wa = get_api_data(weather_information_url, access_key)\n",
    "\n",
    "    if response_tt == 200 and response_ta == 200 and response_wa == 200:\n",
    "        status = \"Success\"\n",
    "        logging.info(status)\n",
    "    else:\n",
    "        status = \"Failed\"\n",
    "        logging.error(status)\n",
    "\n",
    "    # add pull_date_time\n",
    "    df_tt[\"timestamp\"] = timestamp\n",
    "    df_ta[\"timestamp\"] = timestamp\n",
    "    df_wa[\"timestamp\"] = timestamp\n",
    "\n",
    "    # convert dict columns to json\n",
    "    convert_dict_to_json(df_tt)\n",
    "    convert_dict_to_json(df_ta)\n",
    "    convert_dict_to_json(df_wa)\n",
    "\n",
    "    df_api_fetch = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"timestamp\": timestamp,\n",
    "                \"travel_times_response\": response_tt,\n",
    "                \"traffic_alerts_response\": response_ta,\n",
    "                \"weather_alerts_response\": response_wa,\n",
    "                \"status\": status,\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return df_api_fetch, df_tt, df_ta, df_wa, status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract APIs and Load to MySQL Database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function: extract_load_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 13:10:57,542 - INFO - Data fetched successfully.\n",
      "2025-02-15 13:10:57,224 - INFO - Data fetched successfully.\n",
      "2025-02-15 13:10:57,949 - INFO - Data fetched successfully.\n",
      "2025-02-15 13:10:58,130 - INFO - Success\n",
      "2025-02-15 13:10:58,307 - INFO - *** Connected to database ***\n",
      "2025-02-15 13:10:58,844 - INFO - *** Appending to history tables ***\n",
      "2025-02-15 13:10:59,226 - INFO - api_fetch_hist (append) uploaded successfully.\n",
      "2025-02-15 13:10:59,675 - INFO - time_travel_hist (append) uploaded successfully.\n",
      "2025-02-15 13:11:00,022 - INFO - traffic_alerts_hist (append) uploaded successfully.\n",
      "2025-02-15 13:11:00,352 - INFO - weather_alerts_hist (append) uploaded successfully.\n",
      "2025-02-15 13:11:00,534 - INFO - *** Updating raw tables ***\n",
      "2025-02-15 13:11:01,318 - INFO - api_fetch (replace) uploaded successfully.\n",
      "2025-02-15 13:11:02,179 - INFO - time_travel_raw (replace) uploaded successfully.\n",
      "2025-02-15 13:11:02,990 - INFO - traffic_alerts_raw (replace) uploaded successfully.\n",
      "2025-02-15 13:11:03,794 - INFO - weather_alerts_raw (replace) uploaded successfully.\n",
      "2025-02-15 13:11:09,610 - INFO - CALL TransformTravelTime result: <sqlalchemy.engine.cursor.CursorResult object at 0x7feee12f7f40>\n",
      "2025-02-15 13:11:09,785 - INFO - CALL TransformTrafficAlerts result: <sqlalchemy.engine.cursor.CursorResult object at 0x7feee13c32e0>\n",
      "2025-02-15 13:11:09,964 - INFO - CALL TransformWeatherAlerts result: <sqlalchemy.engine.cursor.CursorResult object at 0x7feee1374460>\n"
     ]
    }
   ],
   "source": [
    "def extract_load_transform():\n",
    "    \"\"\"\n",
    "    Extracts data from APIs, loads it into a database, and performs transformations.\n",
    "\n",
    "    This function automates the ETL (Extract, Load, Transform) process by:\n",
    "    1. Fetching travel time, traffic alert, and weather data from APIs.\n",
    "    2. Storing the fetched data into history tables in a database.\n",
    "    3. Updating raw tables with the latest data if the API fetch was successful.\n",
    "    4. Calling stored procedures to transform and process the raw data.\n",
    "\n",
    "    The function logs each step and handles database transactions using SQLAlchemy.\n",
    "    If an error occurs, it logs the failure and returns `None`.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "\n",
    "    Returns:\n",
    "        None: The function performs operations on the database but does not return a value.\n",
    "\n",
    "    Process Flow:\n",
    "        - Fetch API data using `api_update()`.\n",
    "        - Store data in history tables (`api_fetch_hist`, `time_travel_hist`, etc.).\n",
    "        - If the API fetch is successful, replace raw tables with new data.\n",
    "        - Call stored procedures (`TransformTravelTime`, `TransformTrafficAlerts`, etc.).\n",
    "        - Log operations and handle exceptions.\n",
    "\n",
    "    Example Usage:\n",
    "        ```python\n",
    "        extract_load_transform()\n",
    "        ```\n",
    "\n",
    "    Docstring by ChatGPT.\n",
    "    \"\"\"\n",
    "    SLEEP_TIME = 5\n",
    "\n",
    "    try:\n",
    "        # fetch data\n",
    "        df_api_fetch, df_tt, df_ta, df_wa, status = api_update(\n",
    "            TRAVEL_TIMES_URL, TRAFFIC_ALERTS_URL, WEATHER_INFORMATION_URL, api_key\n",
    "        )\n",
    "\n",
    "        # connect to database\n",
    "        with engine.connect() as conn:\n",
    "            logging.info(\"*** Connected to database ***\")\n",
    "\n",
    "            # Append history tables\n",
    "            logging.info(\"*** Appending to history tables ***\")\n",
    "            history_tables = {\n",
    "                \"api_fetch_hist\": df_api_fetch,\n",
    "                \"time_travel_hist\": df_tt,\n",
    "                \"traffic_alerts_hist\": df_ta,\n",
    "                \"weather_alerts_hist\": df_wa,\n",
    "            }\n",
    "            for table, df in history_tables.items():\n",
    "                upload_dataframe(df, table, conn, \"append\")\n",
    "\n",
    "            if status != \"Success\":\n",
    "                logging.warning(\n",
    "                    \"API update was unsuccessful. Skipping raw table updates.\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            # Update raw tables\n",
    "            logging.info(\"*** Updating raw tables ***\")\n",
    "            raw_tables = {\n",
    "                \"api_fetch\": df_api_fetch,\n",
    "                \"time_travel_raw\": df_tt,\n",
    "                \"traffic_alerts_raw\": df_ta,\n",
    "                \"weather_alerts_raw\": df_wa,\n",
    "            }\n",
    "            for table, df in raw_tables.items():\n",
    "                upload_dataframe(df, table, conn, \"replace\")\n",
    "\n",
    "            # Wait before calling stored procedures\n",
    "            sleep(SLEEP_TIME)\n",
    "\n",
    "            # Call stored procedures\n",
    "            stored_procedures = [\n",
    "                \"CALL TransformTravelTime\",\n",
    "                \"CALL TransformTrafficAlerts\",\n",
    "                \"CALL TransformWeatherAlerts\",\n",
    "            ]\n",
    "            results = [conn.execute(text(sp)) for sp in stored_procedures]\n",
    "\n",
    "            # Print results\n",
    "            for sp, result in zip(stored_procedures, results):\n",
    "                logging.info(f\"{sp} result: {result}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.info(\"Database operation failed: \", e)\n",
    "        return None\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call extract_load_transform function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_load_transform()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ads507",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
